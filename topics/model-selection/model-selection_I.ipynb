{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TALENT Course 11\n",
    "## Learning from Data: Bayesian Methods and Machine Learning\n",
    "### York, UK, June 10-28, 2019 \n",
    "$% Some LaTeX definitions we'll use.\n",
    "\\newcommand{\\pr}{\\textrm{p}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian evidence: \n",
    "Please see the full version of the lecture notes here in [html](pub/model_selection-bs.html) and [pdf](pub/model_selection-minted.pdf) formats. The notes contain a somewhat adapted version of Ch. 4.1 in Sivia's book: \"The story of Dr A and Prof B\", which is extremely well written. It also contains a summary of Laplace's method for approximating evidence factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "# Not really needed, but nicer plots\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What order polynomial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the rest of this section, we will use data that was generated from a \"true model\" where x and y satisfy the following:\n",
    "$$\n",
    "y_i = x_i \\sin(x_i)+\\epsilon_i, \n",
    "$$\n",
    "where $0 \\leq x_i \\leq 3$ and the noise is drawn from a normal distribution $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_0)$. The values for 20 regularly spaced points with $\\sigma_0=0.1$ are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# Define our functional form\n",
    "def true_func(x):\n",
    "    return np.sin(x) * x\n",
    "\n",
    "def func(x, dy=0.1):\n",
    "    return np.random.normal(true_func(x), dy)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# select the (noisy) data\n",
    "np.random.seed(0)\n",
    "num_data = 20\n",
    "x_max = 3\n",
    "x = np.linspace(0, x_max, num_data+2)[1:-1]\n",
    "sig0 = 0.1  # try 0.5 or higher or 0.01\n",
    "y = func(x, sig0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.errorbar(x, y, sig0, fmt='o');\n",
    "ax.plot(x, true_func(x), color='red')\n",
    "ax.set(xlabel='x',ylabel='y')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that we have a multiple of models, with varying degree of sophistication. In this example we use polynomials of different orders to represent models of increasing complexity and with an increasing number of model parameters.\n",
    "\n",
    "> Our task is to find which model finds the most support in the given data.\n",
    "\n",
    "It is clear that a more complicated model with more free parameters should be able to fit the data much more closely. But what is the evidence in the data for such a complicated model? Finding the answer to this question is a task for a Bayesian, and the problem is generally known as *Model selection*. \n",
    "\n",
    "Below, we will use an approximate way of computing the Bayesian evidence, namely the Laplace method. In some cases one can also use conjugate priors to simplify the computation of the evidence factor. Or one can use certain sampling methods to compute the evidence numerically. The highlight will be the comparison of different models using the evidences to extract odds-ratios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Model\n",
    "\n",
    "See previous lecture notes, in particular [Parameter estimation III](../bayesian-parameter-estimation/Lecture_Th1a_rjf.pdf) for some more details.\n",
    "\n",
    "In general, we're fitting a $M$-degree polynomial to data, \n",
    "\n",
    "$$\n",
    "y_M(x) = \\sum_{i=0}^M \\theta_i x^i\n",
    "$$\n",
    "\n",
    "where we use $\\theta$ to denote our parameter vector of length $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming all the points are independent, we can find the full log likelihood by adding the individual likelihoods together:\n",
    "$$\n",
    "\\log p(D\\mid\\theta, I) = -\\frac{1}{2}\\sum_{i=1}^N\\left(\\log(2\\pi\\sigma_0^2) + \\frac{\\left[ y_i - y_M(x_i;\\theta)\\right]^2}{\\sigma_0^2}\\right) = \\text{constant} - \\sum_{i=1}^N \\frac{\\left[ y_i - y_M(x_i;\\theta)\\right]^2}{2 \\sigma_0^2}\n",
    "$$\n",
    "\n",
    "We often define the residuals\n",
    "$$\n",
    "R_i = \\left[ y_i - y_M(x_i;\\theta) \\right]/\\sigma_0,\n",
    "$$\n",
    "so that the relevant chi-square sum reads $- \\sum_{i=1}^N R_i^2 / 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def residuals(theta, x=x, y=y, sigma0=sig0):\n",
    "    dy = y - np.polyval(theta,x)\n",
    "    return dy / sigma0\n",
    "\n",
    "# Standard likelihood with Gaussian errors as specified\n",
    "# uniform prior for theta\n",
    "def log_likelihood(theta):\n",
    "    return -0.5 * np.sum(residuals(theta)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Max likelihood fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can maximize the likelihood to find $\\theta$ within a frequentist paradigm. Let us start with a linear fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 1\n",
    "theta_hat = np.polyfit(x, y, degree)\n",
    "x_fit = np.linspace(0, x_max, 1000)\n",
    "y_fit = np.polyval(theta_hat, x_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just plotting this fit, we will compare several different models in the figure below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def fit_degree_n(degree, ax):\n",
    "    \"\"\"Fit a polynomial of order 'degree', return the chi-squared, and plot in axes 'ax'.\"\"\"\n",
    "    theta_hat = np.polyfit(x, y, degree)\n",
    "    x_fit = np.linspace(0, x_max, 1000)\n",
    "    y_fit = np.polyval(theta_hat, x_fit)\n",
    "    \n",
    "    ax.errorbar(x, y, sig0, fmt='o');\n",
    "    ax.plot(x_fit, true_func(x_fit), color='red', alpha=.5)\n",
    "    \n",
    "    ax.text(0.03, 0.96, f\"d = {degree}\", transform=plt.gca().transAxes,\n",
    "            ha='left', va='top',\n",
    "            bbox=dict(ec='k', fc='w', pad=10))\n",
    "    \n",
    "    ax.plot(x_fit, y_fit, '-k')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y$');\n",
    "    \n",
    "    return -2. * log_likelihood(theta_hat)  # chi_squared\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# First figure: plot points with a linear fit\n",
    "nrows=1; ncols=2;\n",
    "fig = plt.figure(figsize=(6*ncols, 6*nrows))\n",
    "\n",
    "num_plots = nrows * ncols\n",
    "degrees = np.zeros(num_plots, dtype=int)\n",
    "chi_sqs_dof = np.zeros(num_plots)\n",
    "print('degree  chi^2/dof')\n",
    "for i in range(num_plots):\n",
    "    ax = fig.add_subplot(nrows, ncols, i+1)\n",
    "    degrees[i] = i\n",
    "    dof = len(x) - (degrees[i])\n",
    "    chi_sqs_dof[i] = fit_degree_n(i, ax) / dof \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Change the degree of the polynomial that is used for the fit. Plot the fits next to each other in a multi-panel figure (e.g., make it 3 by 3).\n",
    "* Compute the chi-squared value per degree of freedom (the ingredients are already included in the script) and plot that as a function of the degree of the polynomial. Is it decreasing, or is there a peak?\n",
    "* For which degree polynomials would you say that you're underfitting the data?\n",
    "* For which degree polynomials would you say that you're overfitting the data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross validation\n",
    "This section will introduce the frequentist tool of cross-validation. This approach is used extensively within machine-learning as a way to handle overfitting and underfitting, bias and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the cross-validation points\n",
    "ncross=5\n",
    "index_cv = np.random.choice(range(len(x)), ncross, replace=False)\n",
    "\n",
    "x_cv=x[index_cv]\n",
    "y_cv=y[index_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data is then\n",
    "x_train = np.delete(x,index_cv)\n",
    "y_train = np.delete(y,index_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and CV errors as a function of polynomial degree d\n",
    "degree_max = 13\n",
    "d = np.arange(0, degree_max+1)\n",
    "training_err = np.zeros(d.shape)\n",
    "crossval_err = np.zeros(d.shape)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "for i in range(len(d)):\n",
    "    p = np.polyfit(x_train, y_train, d[i])\n",
    "    training_err[i] = np.sqrt(np.sum((np.polyval(p, x_train) - y_train) ** 2)\n",
    "                              / len(y_train))\n",
    "    crossval_err[i] = np.sqrt(np.sum((np.polyval(p, x_cv) - y_cv) ** 2)\n",
    "                              / len(y_cv))\n",
    "\n",
    "ax.plot(d, crossval_err, '--k', label='cross-validation')\n",
    "ax.plot(d, training_err, '-k', label='training')\n",
    "ax.plot(d, sig0 * np.ones(d.shape), ':k')\n",
    "\n",
    "ax.set_xlim(0, degree_max)\n",
    "# You might need to change the y-scale if you make modifications to the training data\n",
    "ax.set_ylim(0, 0.8)\n",
    "\n",
    "ax.set_xlabel('polynomial degree')\n",
    "ax.set_ylabel('rms error')\n",
    "ax.legend(loc='best');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Questions\n",
    "\n",
    "* Can you see the transition from underfit to overfit in this figure?\n",
    "* What would you say is the degree of polynomial that is supported by the data?\n",
    "* Try changing the size of the cross-validation and training sets. Does the conclusions become more/less clear?\n",
    "* Does the results change between different runs with the same number of CV samples? If so, why?\n",
    "* K-fold cross validation is a popular variant of CV. It addresses some issues with the sensitivity to the actual choice of which data is used for training and validation.  What do you think that it means, and what is the possible drawback if you have a computational expensive model?\n",
    "* Leave-one-out is another variant. For linear regression problems, this type of cross-validation can actually be performed without having to do multiple fits. What do you think that it means?\n",
    "* It is common to divide the data into a training set, a cross-validation set, and a test set. What do you think is the purpose of having three different sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try the Bayesian approach and actually compute the evidence for these different models. We will use the Laplace method for computing the norm of the posterior distribution (i.e. approximating it as a single Gaussian).\n",
    "\n",
    "We use simple uniform priors for the model parameters:\n",
    "$$\n",
    "p(\\theta_i|I) = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\frac{1}{\\theta_\\mathrm{max} - \\theta_\\mathrm{min}} & \\text{for } \\theta_\\mathrm{min} \\leq \\theta_i \\leq \\theta_\\mathrm{max}, \\\\\n",
    "0 & \\text{otherwise},\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "which means that the posterior will be\n",
    "$$\n",
    "p(\\theta | D, I) = \\frac{1}{(\\theta_\\mathrm{max} - \\theta_\\mathrm{min})^K} \\exp\\left( -\\chi^2 / 2\\right),\n",
    "$$\n",
    "within the allowed prior region for the $K$ parameters and zero elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assuming that the peak of the Gaussian is located at $\\theta^*$, well inside the prior region; we can easily approximate the integral\n",
    "$$\n",
    "Z_p = \\int d^K \\theta p(\\theta | D, I),\n",
    "$$\n",
    "using Laplace's method (see lecture notes here in [html](pub/model_selection-bs.html) and [pdf](pub/model_selection-minted.pdf) formats). With this particular choice of prior, and again under the assumption that the cut at the edges does not change the integral over the multidimensional integral, we get\n",
    "$$\n",
    "Z_p \\approx \\frac{1}{(\\theta_\\mathrm{max} - \\theta_\\mathrm{min})^K} \\exp\\left( -\\chi^2(\\theta^*) / 2\\right) \\frac{\\sqrt{(2\\pi)^K}}{\\sqrt{\\det(\\Sigma^{-1})}},\n",
    "$$\n",
    "where $\\Sigma^{-1}_{ij} = \\partial^2\\chi^2/\\partial \\theta_i \\partial \\theta_j$ (i.e. the Hessian) evaluated at the maximum $\\theta^*$.\n",
    "\n",
    "Note that for this linear regression problem we can get all these quantities ($\\theta^*$, $\\Sigma$) via linear algebra. See, e.g., Dick's [lecture notes](https://github.com/NuclearTalent/Bayes2019/blob/master/topics/bayesian-parameter-estimation/Lecture_Th1a_rjf.pdf) or Hogg's nice paper: [Data analysis recipes: Fitting a model to data](https://arxiv.org/abs/1008.4686). Below, we will use `numpy.polyfit` to extract the relevant quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a uniform prior for all parameters in [-10,10]\n",
    "theta_max = 10\n",
    "theta_min = -10\n",
    "prior_range = theta_max - theta_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "degree_max = 6\n",
    "evidence = np.zeros(degree_max+1)\n",
    "print(\"Degree  P*          Best fit parameters: \")\n",
    "for ideg,deg in enumerate(range(degree_max+1)):\n",
    "    theta_hat, Cov = np.polyfit(x, y, deg,cov='unscaled')\n",
    "    if not (np.all(theta_hat < theta_max) and np.all(theta_hat > theta_min)):\n",
    "        print(\"Outside of prior range\")\n",
    "    P_star = np.exp(log_likelihood(theta_hat))\n",
    "    H=np.linalg.inv(Cov)\n",
    "    evidence[ideg] = P_star * np.sqrt((2*np.pi)**deg / np.linalg.det(H)) / prior_range**deg\n",
    "    print (f'   {deg}    {P_star:.2e}  ',('{:5.2f} '*len(theta_hat)).format(*theta_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "d = np.arange(0, degree_max+1)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(d,evidence,'o-')\n",
    "\n",
    "ax.set_xlabel('polynomial degree')\n",
    "ax.set_ylabel('evidence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Can you see the transition from underfit to overfit in this figure?\n",
    "* What would you say is the degree of polynomial that is supported by the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds ratio table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* What happens when you change the number of the generated data?\n",
    "* What happens when you change the range of the generated data?\n",
    "* What happens when you change the error of the generated data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Odds-ratios\n",
    "Quoting the well-known paper by Trotta:\n",
    "[Bayes in the sky: Bayesian inference and model selection in cosmology](https://arxiv.org/abs/0803.4089) we can quantify an empirical scale for evaluating the strength of evidence when comparing two models,\n",
    "![Bayes in the Sky](trotta.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Create a table of odds-ratios to select between pairs of the different-order polynomial models, given that the ratio of prior probabilities for the different models is unity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
