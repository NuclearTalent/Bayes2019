{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear regression\n",
    "\n",
    "This notebook was adapted from a course at Duke University.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will show how to estimate regression parameters using a simple linear model\n",
    "\n",
    "$$\n",
    "y \\sim ax + b\n",
    "$$\n",
    "\n",
    "We can restate the linear model $$y = ax + b + \\epsilon$$ as sampling from a probability distribution\n",
    "\n",
    "$$\n",
    "y \\sim \\mathcal{N}(ax + b, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Now we can use `PyMC3` to estimate the parameters $a$, $b$ and $\\sigma$. We will assume the following priors\n",
    "\n",
    "$$\n",
    "a \\sim \\mathcal{N}(0, 100) \\\\\n",
    "b \\sim \\mathcal{N}(0, 100) \\\\\n",
    "\\sigma \\sim | \\mathcal{N(0, 1)} |\n",
    "$$\n",
    "\n",
    "Note: It may be useful to scale observed values to have zero mean and unit standard deviation to simplify choice of priors. However, you may need to back-transform the parameters to interpret the estimated values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('darkgrid')\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import scipy.stats as stats\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "theano.config.warn.round=False\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Setting up and fitting linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# observed data\n",
    "np.random.seed(123)\n",
    "n = 11\n",
    "_a = 6\n",
    "_b = 2\n",
    "x = np.linspace(0, 1, n)\n",
    "y = _a*x + _b + np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "niter = 1000\n",
    "with pm.Model() as linreg:\n",
    "    a = pm.Normal('a', mu=0, sd=100)\n",
    "    b = pm.Normal('b', mu=0, sd=100)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    y_est = a*x + b     \n",
    "    likelihood = pm.Normal('y', mu=y_est, sd=sigma, observed=y)\n",
    "\n",
    "    trace = pm.sample(niter, random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace, varnames=['a', 'b'])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Make a plot with the true result and draws from the end of the trace.\n",
    "\n",
    "plt.scatter(x, y, s=30, label='data')\n",
    "for a_, b_ in zip(trace['a'][-100:], trace['b'][-100:]):\n",
    "    plt.plot(x, a_*x + b_, c='gray', alpha=0.1)\n",
    "plt.plot(x, _a*x + _b, label='true regression line', lw=3., c='red')\n",
    "plt.legend(loc='best')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Posterior predictive checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ppc = pm.sample_posterior_predictive(trace, samples=500, model=linreg, size=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot([np.mean(n) for n in ppc['y']], kde=True)\n",
    "plt.axvline(np.mean(y), color='red')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the GLM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    pm.glm.GLM.from_formula('y ~ x', df)\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace, varnames=['Intercept', 'x'])\n",
    "pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "pm.plot_posterior_predictive_glm(trace, samples=200)\n",
    "plt.plot(x, _a*x + _b, label='true regression line', lw=3., c='red')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Robust linear regression\n",
    "\n",
    "If our data has outliers, we can perform a robust regression by modeling errors from a fatter tailed distribution than the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# observed data\n",
    "np.random.seed(123)\n",
    "n = 11\n",
    "_a = 6\n",
    "_b = 2\n",
    "x = np.linspace(0, 1, n)\n",
    "y = _a*x + _b + np.random.randn(n)\n",
    "y[5] *=10 # create outlier\n",
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Effect of outlier on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "niter = 1000\n",
    "with pm.Model() as linreg:\n",
    "    a = pm.Normal('a', mu=0, sd=100)\n",
    "    b = pm.Normal('b', mu=0, sd=100)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    y_est = pm.Deterministic('mu', a*x + b)\n",
    "    y_obs = pm.Normal('y_obs', mu=y_est, sd=sigma, observed=y)\n",
    "\n",
    "    trace = pm.sample(niter, random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with linreg:\n",
    "    pp = pm.sample_posterior_predictive(trace, samples=100, vars=[a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, s=30, label='data')\n",
    "for a_, b_ in zip(pp['a'], pp['b']):\n",
    "    plt.plot(x, a_*x + b_, c='gray', alpha=0.1)\n",
    "plt.plot(x, _a*x + _b, label='true regression line', lw=3., c='red')\n",
    "plt.legend(loc='upper left')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Use a T-distribution for the errors for a more robust fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note how we sample [a, b] as a vector Î² using the `shape` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "niter = 1000\n",
    "with pm.Model() as robust_linreg:\n",
    "    beta = pm.Normal('beta', 0, 10, shape=2)\n",
    "    nu = pm.Exponential('nu', 1/len(x))\n",
    "    sigma = pm.HalfCauchy('sigma', beta=1)\n",
    "\n",
    "    y_est = beta[0] + beta[1]*x\n",
    "    y_obs = pm.StudentT('y_obs', mu=y_est, sd=sigma, nu=nu, observed=y)\n",
    "\n",
    "    trace = pm.sample(niter, random_seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with robust_linreg:\n",
    "    pp = pm.sample_posterior_predictive(trace, samples=100, vars=[beta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, s=30, label='data')\n",
    "for a_, b_ in zip(pp['beta'][:,1], pp['beta'][:,0]):\n",
    "    plt.plot(x, a_*x + b_, c='gray', alpha=0.1)\n",
    "plt.plot(x, _a*x + _b, label='true regression line', lw=3., c='red')\n",
    "plt.legend(loc='upper left')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using the GLM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    pm.glm.GLM.from_formula('y ~ x', df, \n",
    "                            family=pm.glm.families.StudentT())\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "pm.plot_posterior_predictive_glm(trace, samples=200)\n",
    "plt.plot(x, _a*x + _b, label='true regression line', lw=3., c='red')\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:talent-env]",
   "language": "python",
   "name": "conda-env-talent-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
